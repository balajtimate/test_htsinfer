{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Barplots for organism match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_most_common = data.loc[data['org'].isin(\n",
    "    ['hsapiens', 'mmusculus', 'athaliana', 'dmelanogaster', 'drerio', 'rnorvegicus', 'zmays', 'mmulatta', 'scerevisiae', 'osativa']\n",
    ")].copy()\n",
    "\n",
    "category_counts_all = np.unique(data_most_common['match_org_all'], return_counts=True)\n",
    "percentages_all = category_counts_all[1] / len(data_most_common) * 100\n",
    "\n",
    "category_counts_100 = np.unique(data_most_common['match_org_100'], return_counts=True)\n",
    "percentages_100 = category_counts_100[1] / len(data_most_common) * 100\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(10, 5), gridspec_kw={'width_ratios': [.5, .5]})\n",
    "g = sns.barplot(data=data_most_common, x=category_counts_all[0], y=percentages_all, palette=\"Blues\", ax=ax[0])\n",
    "g.set(xlabel=\"Match Category\", ylabel=\"Percentage\")\n",
    "g.bar_label(g.containers[0], fmt='%.f%%')\n",
    "g.set(title='Matched organism %, 10 most frequent organisms' + '\\nAll organism transcripts' \n",
    "       + '\\nLibrary source min-match percentage: 2' \n",
    "       + '\\nLibrary source min frequency ratio: 2')\n",
    "f = sns.barplot(data=data_most_common, x=category_counts_100[0], y=percentages_100, palette=\"Blues\", ax=ax[1])\n",
    "f.set(xlabel=\"Match Category\", ylabel=\"Percentage\")\n",
    "f.bar_label(f.containers[0], fmt='%.f%%')\n",
    "f.set(title='Matched organism %, 10 most frequent organisms' + '\\n100 most frequent organism transcripts' \n",
    "       + '\\nLibrary source min-match percentage: 2' \n",
    "       + '\\nLibrary source min frequency ratio: 2')\n",
    "plt.savefig(\"org_test_results.png\", dpi=250, bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms for predicted adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of 1st predicted adapter percent #1\n",
    "# # Drop 0 percentages of both SE and PE reads\n",
    "result_final_n = result_final.drop(result_final[\n",
    "    (result_final['1_percent_1'] == 0) &\n",
    "    (result_final['2_percent_1'] == 0) |\n",
    "    (result_final['1_percent_1'] == 0) &\n",
    "    result_final['2_percent_1'].isna()].index)\n",
    "all_percent = pd.concat([result_final_n['1_percent_1'],\n",
    "                            result_final_n['2_percent_1']])\n",
    "all_percent = all_percent[all_percent != 0]\n",
    "fig, axs = plt.subplots(1, figsize=[8, 8])\n",
    "sns.histplot(data=all_percent, binwidth=2).set(\n",
    "    title='Fraction of reads containing most '\n",
    "            + 'prevalent adapter\\nID: ' + str(results_folder)\n",
    "            + '\\nNo. of records: ' + str(records)\n",
    "            + '\\nRead layout min-match percentage: ' + str(min_match)\n",
    "            + '\\nRead layout min frequency ratio: ' + str(min_freq))\n",
    "plt.xlim(0, 100)\n",
    "plt.savefig(str(RESULTS_HTS_DIR) + '/' + str(results_folder)\n",
    "            + '/2_Hist_1st_pred_adapter_full.png', dpi=100)\n",
    "\n",
    "# Histogram of 1st predicted adapter percent #2\n",
    "fig, axs = plt.subplots(1, figsize=[8, 8])\n",
    "sns.histplot(data=all_percent, binwidth=0.2).set(\n",
    "    title='Fraction of reads containing most '\n",
    "            + 'prevalent adapter\\nID: '\n",
    "            + str(results_folder)\n",
    "            + '\\nNo. of records: ' + str(records)\n",
    "            + '\\nRead layout min-match percentage: ' + str(min_match)\n",
    "            + '\\nRead layout min frequency ratio: ' + str(min_freq))\n",
    "plt.xlim(0, 10)\n",
    "plt.savefig(str(RESULTS_HTS_DIR) + '/' + str(results_folder)\n",
    "            + '/3_Hist_1st_pred_adapter_10.png', dpi=100)\n",
    "\n",
    "# Histogram of 1st vs 2nd predicted adapter ratio\n",
    "result_final_n = result_final.drop(result_final[\n",
    "    (result_final['1_percent_1'] == 0) &\n",
    "    (result_final['2_percent_1'] == 0) |\n",
    "    (result_final['1_percent_1'] == 0) &\n",
    "    result_final['2_percent_1'].isna()].index)\n",
    "result_final_n['1_ratio'] = (\n",
    "    result_final_n['1_percent_1'] / (\n",
    "        result_final_n['1_percent_2'] + 0.01))\n",
    "result_final_n['2_ratio'] = (\n",
    "    result_final_n['2_percent_1'] / (\n",
    "        result_final_n['2_percent_2'] + 0.01))\n",
    "all_ratios = pd.concat(\n",
    "    [result_final_n['1_ratio'], result_final_n['2_ratio']])\n",
    "fig, axs = plt.subplots(1, figsize=[8, 8])\n",
    "sns.histplot(data=all_ratios).set(\n",
    "    title='Fraction of reads with most prevalent adapter '\n",
    "    + 'vs. second most prevalent\\nID: '\n",
    "    + str(results_folder)\n",
    "    + '\\nNo. of records: ' + str(records)\n",
    "    + '\\nRead layout min-match percentage: ' + str(min_match)\n",
    "    + '\\nRead layout min frequency ratio: ' + str(min_freq),\n",
    "    xscale=\"log\")\n",
    "plt.savefig(str(RESULTS_HTS_DIR) + '/' + str(results_folder)\n",
    "            + '/4_Hist_1st_vs_2nd_pred_adapter_ratio.png', dpi=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Barplots for performance times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5 = data.loc[data['process'].isin(['processing_dur','extracting_dur','kallisto_quant_dur','alignment_dur','cutadapt_dur'])].copy()\n",
    "data_total = data.loc[data['process'] == 'total_dur'].copy()\n",
    "\n",
    "# Replace NaN values in 'duration' column with zeros\n",
    "data_5['duration'] = data_5['duration'].fillna('00:00:00')\n",
    "data_total['duration'].fillna('00:00:00', inplace=True)\n",
    "\n",
    "# Convert 'duration' column to timedelta format\n",
    "data_5['duration'] = pd.to_timedelta(data_5['duration'])\n",
    "data_total['duration'] = pd.to_timedelta(data_total['duration'])\n",
    "\n",
    "# Extract total seconds from timedelta values and convert to numeric\n",
    "data_5['duration'] = data_5['duration'].dt.total_seconds()\n",
    "data_total['duration'] = data_total['duration'].dt.total_seconds()\n",
    "\n",
    "fig, ax =plt.subplots(1,2, figsize=(9, 5), gridspec_kw={'width_ratios': [.80, .20]})\n",
    "g = sns.barplot(data=data_5, x='process', y='duration', hue='perf_group', errorbar='se', palette=\"bright\", alpha=.6, ax=ax[0])\n",
    "g.set(xlabel=\"\", ylabel=\"Duration (seconds)\")\n",
    "g.set_xticklabels([\"Process records\", \"Extract read length\", \"Kallisto quantification\", \"STAR Alignment\", \"Cutadapt\"], rotation=45)\n",
    "g.legend(title=\"No. of records\")\n",
    "\n",
    "f = sns.barplot(data=data_total, x='process', y='duration', hue='perf_group', errorbar='se', palette=\"bright\", alpha=.6, ax=ax[1])\n",
    "f.set(xlabel=\"\", ylabel=\"\")\n",
    "f.set_xticklabels([\"Total HTSinfer run\"], rotation=45)\n",
    "f.legend_.remove()\n",
    "sns.despine()\n",
    "plt.savefig(\"perf_test_results.png\", dpi=250, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
